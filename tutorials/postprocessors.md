# :scroll: List of Postprocessors
*This file is automatically generated with `docgenerator.py`.*

The following postprocessors can be imported from the package `pygrank.algorithms.postprocess`.
Constructor details are provided, including arguments inherited from and passed to parent classes.
All of them can be used through the code patterns presented at the library's [documentation](documentation.md).  
1. [AdHocFairness](#postprocessor-adhocfairness)
2. [BoostedSeedOversampling](#postprocessor-boostedseedoversampling)
3. [FairPersonalizer](#postprocessor-fairpersonalizer)
4. [FairWalk](#postprocessor-fairwalk)
5. [Normalize](#postprocessor-normalize)
6. [Ordinals](#postprocessor-ordinals)
7. [SeedOversampling](#postprocessor-seedoversampling)
8. [Sweep](#postprocessor-sweep)
9. [Tautology](#postprocessor-tautology)
10. [Threshold](#postprocessor-threshold)
11. [Transformer](#postprocessor-transformer)

### <kbd>Postprocessor</kbd> AdHocFairness

Adjusts node scores so that the sum of sensitive nodes is moved closer to the sum of non-sensitive ones based on 
ad hoc literature assumptions about how unfairness is propagated in graphs. 
Initializes the fairness-aware postprocessor. 

Args: 
 * *ranker:* The base ranking algorithm. 
 * *method:* The method with which to adjust weights. If "O" (default) an optimal gradual adjustment is performed [tsioutsiouliklis2020fairness]. If "B" node scores are weighted according to whether the nodes are sensitive, so that the sum of sensitive node scores becomes equal to the sum of non-sensitive node scores [tsioutsiouliklis2020fairness].  If "fairwalk" the graph is pre-processed so that, when possible, walks are equally probable to visit sensitive or non-sensitive nodes at non-restarting iterations [rahman2019fairwalk]. 
 * *eps:* A small value to consider rank redistribution to have converged. Default is 1.E-12. 

### <kbd>Postprocessor</kbd> BoostedSeedOversampling

Iteratively performs seed oversampling and combines found ranks by weighting them with a Boosting scheme. 
Initializes the class with a base ranker and the boosting scheme's parameters. 

Attributes: 
 * *ranker:* The base ranker instance. 
 * *objective:* Optional. Can be either "partial" (default) or "naive". 
 * *oversample_from_iteration:* Optional. Can be either "previous" (default) to oversample the ranks of the previous iteration or "original" to always ovesample the given personalization. 
 * *weight_convergence:* Optional.  A ConvergenceManager that helps determine whether the weights placed on boosting iterations have converged. If None (default), initialized with ConvergenceManager(error_type=pyrgank.MaxDifference, tol=0.001, max_iters=100) 

Example:

```python 
>>> from pygrank.algorithms import PageRank, BoostedSeedOversampling 
>>> graph, seed_nodes = ... 
>>> algorithm = BoostedSeedOversampling(PageRank(alpha=0.99)) 
>>> ranks = algorithm.rank(graph, personalization={1 for v in seed_nodes}) 
```


### <kbd>Postprocessor</kbd> FairPersonalizer

A personalization editing scheme that aims to edit graph signal priors (i.e. personalization) to produce 
disparate 
Instantiates a personalization editing scheme that trains towards optimizing 
retain_rank_weight*error_type(original scores, editing-induced scores) 
+ pRule_weight*min(induced score pRule, target_pRule) 

Args: 
 * *ranker:* The base ranking algorithm. 
 * *target_pRule:* Up to which value should pRule be improved. pRule values greater than this are not penalized further. 
 * *retain_rank_weight:* Can be used to penalize deviations from original posteriors due to editing. Use the default value 1 unless there is a specific reason to scale the error. Higher values correspond to tighter maintenance of original posteriors, but may not improve fairness as much. 
 * *pRule_weight:* Can be used to penalize low pRule values. Either use the default value 1 or, if you want to place most emphasis on pRule maximization (instead of trading-off between fairness and posterior preservation) 10 is a good empirical starting point. 
 * *error_type:* The supervised measure used to penalize deviations from original posterior scores. pygrank.KLDivergence (default) uses is used in [krasanakis2020prioredit]. pygrank.Error is used by the earlier [krasanakis2020fairconstr]. The latter does not induce fairness as well on average, but is sometimes better for specific graphs. 
 * *parameter_buckets:* How many sets of parameters to be used to . Default is 1. More parameters could be needed to to track, but running time scales **exponentially** to these (with base 4). 
 * *max_residual:* An upper limit on how much the original personalization is preserved, i.e. a fraction of it in the range [0, max_residual] is preserved. Default is 1 and is introduced by [krasanakis2020prioredit], but 0 can be used for exact replication of [krasanakis2020fairconstr]. 

### <kbd>Postprocessor</kbd> FairWalk
 

### <kbd>Postprocessor</kbd> Normalize

Normalizes ranks by dividing with their maximal value. 
Initializes the class with a base ranker instance. Args are automatically filled in and 
re-ordered if at least one is provided. 

Args: 
 * *ranker:* The base ranker instance. A Tautology() ranker is created if None (default) was specified. 
 * *method:* Divide ranks either by their "max" (default) or by their "sum" or make the lie in the "range" [0,1] by subtracting their mean before diving by their max. 

Example:

```python 
>>> from pygrank.algorithms.postprocess import Normalize 
>>> graph, personalization, algorithm = ... 
>>> algorithm = Normalize(0.5, algorithm) # sets ranks >= 0.5 to 1 and lower ones to 0 
>>> ranks = algorithm.rank(graph, personalization) 
```


Example (same outcome, simpler one-liner):

```python 
>>> from pygrank.algorithms.postprocess import Normalize 
>>> graph, personalization, algorithm = ... 
>>> ranks = Normalize(0.5).transform(algorithm.rank(graph, personalization)) 
```


### <kbd>Postprocessor</kbd> Ordinals

Converts ranking outcome to ordinal numbers. 
The highest rank is set to 1, the second highest to 2, etc. 
Initializes the class with a base ranker instance. 

Args: 
 * *ranker:* Optional. The base ranker instance. A Tautology() ranker is created if None (default) was specified. 

### <kbd>Postprocessor</kbd> SeedOversampling

Performs seed oversampling on a base ranker to improve the quality of predicted seeds. 
Initializes the class with a base ranker. 

Attributes: 
 * *ranker:* The base ranker instance. 
 * *method:* Optional. Can be "safe" (default) to oversample based on the ranking scores of a preliminary base ranker run or "neighbors" to oversample the neighbors of personalization nodes. 

Example:

```python 
>>> from pygrank.algorithms import PageRank, SeedOversampling 
>>> graph, seed_nodes = ... 
>>> algorithm = SeedOversampling(PageRank(alpha=0.99)) 
>>> ranks = algorithm.rank(graph, personalization={1 for v in seed_nodes}) 
```


### <kbd>Postprocessor</kbd> Sweep

Applies a sweep procedure that divides personalized node ranks by corresponding non-personalized ones. 
Initializes the sweep procedure. 

Args: 
 * *ranker:* The base ranker instance. 
 * *uniform_ranker:* Optional. The ranker instance used to perform non-personalized ranking. If None (default) the base ranker is used. 

### <kbd>Postprocessor</kbd> Tautology

Returns ranks as-are. 
Can be used as a baseline against which to compare other postprocessors. 

### <kbd>Postprocessor</kbd> Threshold

Converts ranking outcome to binary values based on a threshold value. 
Initializes the Threshold postprocessing scheme. Args are automatically filled in and 
re-ordered if at least one is provided. 

Args: 
 * *ranker:* Optional. The base ranker instance. A Tautology() ranker is created if None (default) was specified. 
 * *threshold:* Optional. The minimum numeric value required to output rank 1 instead of 0. If "gap" (default) then its value is automatically determined based on the maximal percentage increase between consecutive ranks. 

Example:

```python 
>>> from pygrank.algorithms.postprocess import Threshold 
>>> graph, personalization, algorithm = ... 
>>> algorithm = Threshold(algorithm, 0.5) # sets ranks >= 0.5 to 1 and lower ones to 0 
>>> ranks = algorithm.rank(graph, personalization) 
```


Example (same outcome):

```python 
>>> from pygrank.algorithms.postprocess import Threshold 
>>> graph, personalization, algorithm = ... 
>>> ranks = Threshold(0.5).transform(algorithm.rank(graph, personalization)) 
```


### <kbd>Postprocessor</kbd> Transformer

Applies an element-by-element transformation on a graph signal based on a given expression. 
Initializes the class with a base ranker instance. Args are automatically filled in and 
re-ordered if at least one is provided. 

Args: 
 * *ranker:* Optional. The base ranker instance. A Tautology() ranker is created if None (default) was specified. 
 * *expr:* Optional. A lambda expression to apply on each element. The transformer will automatically try to apply it on the backend array representation of the graph signal first, so prefer use of backend functions for faster computations. For example, backend.exp (default) should be preferred instead of math.exp, because the former can directly parse numpy arrays, tensors, etc. 

Example:

```python 
>>> from pygrank.algorithms import Normalize, Transformer 
>>> from pygrank import backend 
>>> graph, personalization, algorithm = ... 
>>> r1 = Normalize(algorithm, "sum").rank(graph, personalization) 
>>> r2 = Transformer(algorithm, lambda x: x/backend.sum(x)).rank(graph, personalization) 
>>> print(sum(abs(r1[v]-r2[v]) for v in graph)) 
```

