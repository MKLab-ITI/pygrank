# :scroll: List of Tuners
*This file is automatically generated with `docgenerator.py`.*

The following tuning mechanisms can be imported from the package `pygrank.algorithms.autotune`.
Constructor details are provided, including arguments inherited from and passed to parent classes.
All of them can be used through the code patterns presented at the library's [documentation](documentation.md).  
1. [ParameterTuner](#kbdtunerkbd-parametertuner)

### <kbd>Tuner</kbd> ParameterTuner

Tunes a parameterized version of node ranking algorithms under a specific measure by splitting the personalization 
in training and test sets. 
Instantiates the tuning mechanism. 

Args: 
 * *ranker_generator:* A callable that constructs a ranker based on a list of parameters. If None (default) then a pygrank.algorithms.learnable.GenericGraphFilter is constructed with automatic normalization and assuming immutability (this is the most common setting). These parameters can be overriden and other ones can be passed to the algorithm's constructor simply by including them in kwargs. 
 * *measure:* Callable to constuct a supervised measure with given known node scores and an iterable of excluded scores. 
 * *fraction_of_training:* A number in (0,1) indicating how to split provided graph signals into training and validaton ones by randomly sampling training nodes to meet the required fraction of all graph nodes. Default is 0.5. 
 * *combined_prediction:* If True (default), after the best version of algorithms is determined, the whole personalization is used to produce the end-result. Otherwise, only the training portion of the training-validation split is used. 
 * *kwargs:* Additional arguments can be passed to pygrank.algorithms.autotune.optimization.optimize. Otherwise, the respective arguments are retrieved from the variable *default_tuning_optimization*, which is crafted for fast convergence of the default ranker_generator. Make sure to declare both the upper **and** the lower bounds of parameter values. 

Example:

```python 
>>> from pygrank.algorithms.autotune import ParameterTuner 
>>> graph, personalization = ... 
>>> tuner = ParameterTuner(measure=AUC, deviation_tol=0.01) 
>>> ranks = tuner.rank(graph, personalization) 
```


Example to tune pagerank's float parameter alpha in the range [0.5, 0.99]:

```python 
>>> from pygrank import PageRank, ParameterTuner 
>>> graph, personalization = ... 
>>> tuner = ParameterTuner(lambda params: PageRank(alpha=params[0]), measure=AUC, deviation_tol=0.01, max_vals=[0.99], min_vals=[0.5]) 
>>> ranks = algorithm.rank(graph, personalization) 
```

