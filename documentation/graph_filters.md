# :scroll: List of Graph Filters
*This file is automatically generated with `docgenerator.py`.*

The following filters can be imported from the package `pygrank.algorithms`.
Constructor details are provided, including arguments inherited from and passed to parent classes.
All of them can be used through the code patterns presented at the library's [documentation](documentation.md#graph-filters). 
1. [GenericGraphFilter](#closedformgraphfilter-genericgraphfilter)
2. [HeatKernel](#closedformgraphfilter-heatkernel)

### <kbd>ClosedFormGraphFilter</kbd> GenericGraphFilter

Implements a graph filter with a specific vector of weight parameters. 
Initializes the graph filter. 

Args: 
 * *weights:* Optional. A list-like object with elements weights[n] proportional to the importance of propagating personalization graph signals n hops away. If None (default) then [0.9]*10 is used. 
 * *krylov_dims:* Optional. Performs the Lanczos method to estimate filter outcome in the Krylov space of the graph with degree equal to the provided dimensions. This considerably speeds up filtering but ends up providing an *approximation* of true graph filter outcomes. If None (default) filters are not computed through their projection the Krylov space, which may yield slower but exact computations. Otherwise, a numeric value equal to the number of latent dimensions is required. 
 * *coefficient_type:* Optional. If "taylor" (default) provided coefficients are considered to define a Taylor expansion. If "chebyshev", they are considered to be the coefficients of a Chebyshev expansion, which provides more robust errors but require normalized personalization. These approaches are **not equivalent** for the same coefficient values; changing this argument could cause adhoc filters to not work as indented. 
 * *optimization_dict:* Optional. If a dict the filter keeps intermediate values that can help it avoid most (if not all) matrix multiplication if it run again for the same graph signal. Setting this parameter to None (default) can save approximately **half the memory** the algorithm uses but slows down tuning iteration times to O(edges) instead of O(nodes). Note that the same dict needs to be potentially passed to multiple algorithms that take the same graph signal as input to see any improvement. 
 * *preprocessor:* Optional. Method to extract a scipy sparse matrix from a networkx graph. If None (default), pygrank.algorithms.utils.preprocessor is used with keyword arguments automatically extracted from the ones passed to this constructor. 
 * *convergence:* Optional. The ConvergenceManager that determines when iterations stop. If None (default), a ConvergenceManager is used with keyword arguments automatically extracted from the ones passed to this constructor. 
 * *personalization_transform:* Optional. A Postprocessor whose `transform` method is used to transform the personalization before applying the graph filter. If None (default) a Tautology is used. 

Example:

```python 
>>> from pygrank import GenericGraphFilter 
>>> algorithm = GenericGraphFilter([0.5, 0.25, 0.125], tol=1.E-9) # tol passed to ConvergenceManager 
```


### <kbd>ClosedFormGraphFilter</kbd> HeatKernel

Heat kernel filter. 
Initializes the HeatKernel filter parameters. 

Args: 
 * *t:* Optional. How many hops until the importance of new nodes starts decreasing. Default value is 5. 
 * *krylov_dims:* Optional. Performs the Lanczos method to estimate filter outcome in the Krylov space of the graph with degree equal to the provided dimensions. This considerably speeds up filtering but ends up providing an *approximation* of true graph filter outcomes. If None (default) filters are not computed through their projection the Krylov space, which may yield slower but exact computations. Otherwise, a numeric value equal to the number of latent dimensions is required. 
 * *coefficient_type:* Optional. If "taylor" (default) provided coefficients are considered to define a Taylor expansion. If "chebyshev", they are considered to be the coefficients of a Chebyshev expansion, which provides more robust errors but require normalized personalization. These approaches are **not equivalent** for the same coefficient values; changing this argument could cause adhoc filters to not work as indented. 
 * *optimization_dict:* Optional. If a dict the filter keeps intermediate values that can help it avoid most (if not all) matrix multiplication if it run again for the same graph signal. Setting this parameter to None (default) can save approximately **half the memory** the algorithm uses but slows down tuning iteration times to O(edges) instead of O(nodes). Note that the same dict needs to be potentially passed to multiple algorithms that take the same graph signal as input to see any improvement. 
 * *preprocessor:* Optional. Method to extract a scipy sparse matrix from a networkx graph. If None (default), pygrank.algorithms.utils.preprocessor is used with keyword arguments automatically extracted from the ones passed to this constructor. 
 * *convergence:* Optional. The ConvergenceManager that determines when iterations stop. If None (default), a ConvergenceManager is used with keyword arguments automatically extracted from the ones passed to this constructor. 
 * *personalization_transform:* Optional. A Postprocessor whose `transform` method is used to transform the personalization before applying the graph filter. If None (default) a Tautology is used. 

Example:

```python 
>>> from pygrank.algorithms import HeatKernel 
>>> algorithm = HeatKernel(t=3, tol=1.E-9) # tol passed to the ConvergenceManager 
>>> graph, seed_nodes = ... 
>>> ranks = algorithm(graph, {v: 1 for v in seed_nodes}) 
```

